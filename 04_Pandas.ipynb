{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MMRES-PyBootcamp/MMRES-python-bootcamp/blob/master/04_Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 4 - Pandas (1<sup>st</sup> part - 80')\n",
    "> An introduction to basic concepts of Pandas. First, you will become familiar with Pandas and its cornerstone variable types: the *Series* and the *DataFrame*. You will learn how to *import data* with Pandas and some tips to perform DataFrame *preliminary exploration* (including a very basic *visual inspection*). In addition, you will learn how to explicitly *access* the data stored in a DataFrame. Finally, you will be introduced to the concepts of DataFrame *boolean indexing* and DataFrame *filtering*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    " * [What is Pandas?](#What-is-Pandas?)\n",
    " * [Series and DataFrames](#Series-and-DataFrames)\n",
    " * [Loading data as a DataFrame](#Loading-data-as-a-DataFrame)\n",
    " * [DataFrame basic inspection](#DataFrame-basic-inspection)\n",
    " * [DataFrame visual inspection](#DataFrame-visual-inspection)\n",
    " * [DataFrame data access](#DataFrame-data-access)\n",
    "   * [Accessing whole columns](#Accessing-whole-columns)\n",
    "   * [Accessing whole rows](#Accessing-whole-rows)\n",
    "   * [Accessing columns and rows simultaneously](#Accessing-columns-and-rows-simultaneously)\n",
    " * [Series methods](#Series-methods)\n",
    " * [DataFrame boolean indexing](#DataFrame-boolean-indexing)\n",
    " * [Filtering DataFrames with boolean indexing](#Filtering-DataFrames-with-boolean-indexing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document is devised as a tool to enable your **self-learning process**. If you get stuck at some step or need any kind of help, please don't hesitate to raise your hand and ask for the teacher's guidance. Along it, you will find some **special cells**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Practice:</b> Practice cells announce exercises that you should try during the current boot camp session. Usually, solutions are provided using hidden cells (look for the dot dot dot symbol \"...\" and click to unravel them and check that your try is correct).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Extension:</b> Extension cells correspond to exercises (or links to contents) that are a bit more advanced. We recommend to try them after the current boot camp session.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Tip:</b> Tip cells just give some advice or complementary information.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"><b>Caveat:</b> Caveat cells warn you about the most common pitfalls one founds when starts his/her path learning Python.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jd6Y3hlZwe_y",
    "tags": []
   },
   "source": [
    "## What is Pandas?\n",
    "\n",
    "You will see in upcoming sessions that [NumPy](https://numpy.org/) makes life a lot easier when dealing with numeric matrices and vectors in Python. However, those used to work with dedicated languages like [R](https://www.r-project.org/), doing data analysis directly with NumPy feels like a step back. Fortunately, some nice folks have written the Python Data Analysis Library (AKA, [Pandas](http://pandas.pydata.org/)). Pandas provides Python with an R-like DataFrame object, produces high quality plots with [matplotlib](https://matplotlib.org/), and nicely integrates with other libraries that expect NumPy arrays such [seaborn](https://seaborn.pydata.org/), [scikit-learn](https://scikit-learn.org/stable/), ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Tip:</b> Don't worry about NumPy. Part of the 4<sup>th</sup> boot camp session ([one notebook](https://github.com/MMRES-PyBootcamp/MMRES-python-bootcamp/blob/master/07_NumPy.ipynb)) will be devoted to this package.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>Extension:</b> Some years ago, other \"bears\" joined the python DataFrame ecosystem: [Polars](https://www.pola.rs/). This is a powerful, and much faster, alternative to Pandas. If you already master Pandas, give a try to Polars and make some performance test to check how efficient it is. Keep in mind that Polars is not available by default in Anaconda3 and you should [install](https://anaconda.org/conda-forge/polars) it first.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series and DataFrames\n",
    "\n",
    "Pandas works with [`Series`](https://pandas.pydata.org/docs/reference/api/pandas.Series.html) of data, that then are column-wise arranged into [`DataFrame`](https://pandas.pydata.org/docs/reference/frame.html) objects. The DataFrame is the object closest to an spreadsheet that we will see throughout the present session. DataFrames, though, given that they are integrated in Python and can be combined with so many different packages, are much more flexible and lightweight than spreadsheets. We usually load Pandas with the `pd` alias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load package with its corresponding alias\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data as a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to load data with Pandas we use functions like [`pd.read_excel()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html) and [`pd.read_csv()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html). As you may have guessed, we choose one or another depending on the format of our input data. For example, [`pd.read_excel()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html) works with `xlsx`, `xls`... and [`pd.read_csv()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) with `csv`, `tsv`, `txt`... These functions have multiple arguments providing great flexibility when importing data, like skipping some rows/columns, specifying the column delimiter or selecting a particular sheet within a spreadsheet. Let's begin by importing the \"toy\" `Spreadsheet.xlsx` from `/MMRES-python-bootcamp/datasets` sub-folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading an Excel SpreadSheet and storing it as a DataFrame called `df_local`\n",
    "df_local = pd.read_excel(io='datasets/Spreadsheet.xlsx')\n",
    "\n",
    "# Return the DataFrame\n",
    "df_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data type of `df`\n",
    "print(type(df_local))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas functions `pd.read_excel()` and `pd.read_csv()` are able to load non-locally stored data. Let's import again `Spreadsheet.xlsx`, but this time straight from the [MMRES Python boot camp GitHub repository](https://github.com/MMRES-PyBootcamp/MMRES-python-bootcamp):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GitHub url towards the SpreadSheet file in xlsx format\n",
    "url_excel = 'https://github.com/MMRES-PyBootcamp/MMRES-python-bootcamp/raw/master/datasets/Spreadsheet.xlsx'\n",
    "\n",
    "# Reading an Excel SpreadSheet and storing it as a DataFrame called `df`\n",
    "df = pd.read_excel(io=url_excel)\n",
    "\n",
    "# Return the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO --> Add here some explanation about the openpyxl issue that some student found at this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import `Spreadsheet.csv` straight from the [MMRES Python boot camp GitHub repository](https://github.com/MMRES-PyBootcamp/MMRES-python-bootcamp):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GitHub url towards the SpreadSheet file in csv format\n",
    "url_csv = 'https://github.com/MMRES-PyBootcamp/MMRES-python-bootcamp/raw/master/datasets/Spreadsheet.csv'\n",
    "\n",
    "# Reading an csv and storing it as a DataFrame called `df`\n",
    "df = pd.read_csv(filepath_or_buffer=url_csv)\n",
    "\n",
    "# Return the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Practice 1:</b>\n",
    "\n",
    "Load the Misophonia data set stored in our [MMRES Python boot camp GitHub repository](https://github.com/MMRES-PyBootcamp/MMRES-python-bootcamp) directly from its *raw view* URL: \n",
    "    \n",
    "1) Open the [link](https://github.com/MMRES-PyBootcamp/MMRES-python-bootcamp) towards MMRES Python boot camp GitHub repository, navigate to the file `Misophonia.txt` stored within the `datasets` folder, and click on it. You should see in your web browser a raw view of the data. \n",
    "\n",
    "2) Copy the hyperlink in your web browser.\n",
    "\n",
    "3) In the 1<sup>st</sup> code cell below, load `Misophonia.txt` straight from GitHub using the hyperlink you just copied. **What happened?**\n",
    "\n",
    "4) In the same code cell, replace `blob` with `raw` in the hyperlink used. **What happened now?**\n",
    "    \n",
    "Un-comment and fill only those code lines with underscores `___`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (1st code cell)\n",
    "#  Reading the Misophonia data set and storing it as a DataFrame called `df_misophonia`\n",
    "# df_misophonia = pd.read_csv(filepath_or_buffer=___, sep='\\t')\n",
    "\n",
    "# Return the Misophonia DataFrame\n",
    "# df_misophonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (1st code cell --> SOLUTION)\n",
    "# Reading the Misophonia data set and storing it as a DataFrame called `df_misophonia`\n",
    "df_misophonia = pd.read_csv(filepath_or_buffer='https://github.com/MMRES-PyBootcamp/MMRES-python-bootcamp/raw/master/datasets/Misophonia.txt', sep='\\t')\n",
    "\n",
    "# Return the Misophonia DataFrame\n",
    "df_misophonia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO --> Add here some explanation about this trick to load content from GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Practice 1 ends here.</b>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Tip:</b> Please be sure you are able to load the Misophonia data set without any problem. You will work in deep with it during the upcoming Group Work sessions.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DataFrame basic inspection\n",
    "\n",
    "Usually, the first thing one should do with a new DataFrame is getting familiar with its *Series* data. Pandas DataFrame objects have many *methods* to this aim, like [`.head()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html), [`.tail()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.tail.html), [`.describe()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame head (first 5 rows)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame tail (last 5 rows)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame (basic) statistical description (only for numeric columns!)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [`.info()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html) method is particularly useful. It gives the name of each *DataFrame column* with their corresponding data type. This method also shows the number of non-null values by *column*, from which we can easily estimate the number of *missing values* (`NaN`) by *column*, and the memory devoted to store the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame general information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to these methods, Pandas DataFrame objects have very useful *attributes* like [`.shape`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shape.html), [`.index`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.index.html) and \n",
    "[`.columns`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.columns.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame shape. Remember: (Rows first, Columns second)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame rows\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Tip:</b> Like *methods*, *attributes* are invoked with the dot `.` symbol. In general, *methods* include a parenthesis (like `.info()`) and *attributes* don't (like `.shape`). Intuitively, you can consider the *attributes* of a Python object as <ins>things it has</ins>, and *methods* as <ins>things it does</ins>. For example, we could imagine a Python object called `cat` with some of the following *attributes* and *methods*:\n",
    "+ Attributes: `cat.age`, `cat.weight`, `cat.gender`, `cat.personality`, `cat.eye_color`, `cat.coat_pattern`, ...\n",
    "+ Methods: `cat.play()`, `cat.purr()`, `cat.meow()`, `cat.chirp()`, `cat.eat()`, `cat.sleep()`, `cat.scratch()`, `cat.pee()`, `cat.poop()`...\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame visual inspection\n",
    "\n",
    "After a basic DataFrame inspection, we can start with a visual exploration. To this aim we can leverage the Pandas DataFrame method [`.plot`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.html) and its related \"sub-methods\" [`.line()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.line.html), [`.bar()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.bar.html), [`.barh()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.barh.html), [`.hist()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.hist.html), [`.box()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.box.html), [`.density()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.density.html), [`.area()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.area.html), [`.pie()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.pie.html), [`.scatter()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.scatter.html), [`.hexbin()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.hexbin.html), ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame line plot\n",
    "df.plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ejercicio"
    ]
   },
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Practice 2:</b>\n",
    "\n",
    "1) In the 1<sup>st</sup> code cell below, get a box plot for the DataFrame `df`.\n",
    "2) In the 2<sup>nd</sup> code cell below, get a scatter plot for the DataFrame `df`. **What happened?**\n",
    "3) Try again buy this time declaring `x=` and `y=` parameters for the `.scatter()` method.\n",
    "\n",
    "Un-comment and fill only those code lines with underscores `___`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ejercicio"
    ]
   },
   "outputs": [],
   "source": [
    "# (1st code cell)\n",
    "#  Generate a box plot for `df`\n",
    "# ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "ejercicio",
     "solucion"
    ]
   },
   "outputs": [],
   "source": [
    "# (1st code cell --> SOLUTION)\n",
    "#  Generate a box plot for `df`\n",
    "df.plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ejercicio"
    ]
   },
   "outputs": [],
   "source": [
    "# (2nd code cell)\n",
    "#  Generate a scatter plot for `df`\n",
    "# ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "ejercicio",
     "solucion"
    ]
   },
   "outputs": [],
   "source": [
    "# (2nd code cell --> SOLUTION)\n",
    "#  Generate a scatter plot for `df`\n",
    "df.plot.scatter(x='Intensity', y='Amplitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Practice 2 ends here.</b>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame data access\n",
    "\n",
    "We can get the information stored in a DataFrame by multiple ways. Here we will present the brackets `[]` syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing whole columns\n",
    "\n",
    "In order to access columns we use the brackets syntax: `df[]`. Passing a list of column names inside the brackets grants access to such columns. Note that there are two pairs of brackets, one enclosing the list of column names (innermost) and one given access to DataFrame columns (outermost):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing DataFrame columns\n",
    "df[['Raw', 'Intensity']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When accessing a single column, we found some subtleties. Doing `df[['RNA']]` returns a single-column DataFrame..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data type of `df[['RNA']]`\n",
    "type(df[['RNA']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... but sometimes it is better to get a Series instead of single-column DataFrame. That's because Series have specific methods that we might need. In order to access a DataFrame and get a Series we directly pass the label of the column we want to the outermost brackets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data type of `df['RNA']`\n",
    "type(df['RNA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"><b>Caveat:</b>\n",
    "\n",
    "* Accessing a DataFrame by passing a *single-label list* to the `df[]` brackets returns a *single-column DataFrame*.\n",
    "* Accessing a DataFrame by passing a *single label* to the `df[]` brackets returns a *Series*.    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing whole rows\n",
    "\n",
    "In order to access rows we need to use [`.loc`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html) followed by the brackets syntax: `df.loc[]`. Passing a list of row indexes inside the brackets grants access to such rows. Again, note that there are two pairs of brackets, one enclosing the list of row indexes (innermost) and one given access to DataFrame rows (outermost):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing DataFrame rows\n",
    "df.loc[[4, 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing columns and rows simultaneously\n",
    "\n",
    "If we want to access the intersection of some columns and rows, we use [`.loc`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html) followed by the brackets syntax with a comma inside: `df.loc[ , ]`. The list with the rows we want goes to the left of the comma and the list with the columns to the right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing a DataFrame column-row intersection\n",
    "df.loc[[4, 1],  ['Raw', 'Intensity']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, you can first put your lists into a variables before accessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing a DataFrame column-row intersection specifying first the list of indices and columns we want\n",
    "list_rows = [4, 1]\n",
    "list_cols = ['Raw', 'Intensity']\n",
    "df.loc[list_rows, list_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like other Python objects, Pandas Series have very useful methods, for example [`.count()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.count.html), [`.sum()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.sum.html), [`.mean()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.mean.html), [`.median()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.median.html), [`.std()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.std.html), [`.min()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.min.html), [`.max()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.max.html)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count 'Intensity' (Series) values\n",
    "print(f\"Count: {df['Intensity'].count()}.\\n\")\n",
    "\n",
    "# Sum 'Intensity' (Series) values\n",
    "print(f\"Sum: {df['Intensity'].sum()}.\\n\")\n",
    "\n",
    "# Get 'Intensity' (Series) mean\n",
    "print(f\"Mean: {df['Intensity'].mean()}.\\n\")\n",
    "\n",
    "# Get 'Intensity' (Series) standard deviation\n",
    "print(f\"Standard deviation: {df['Intensity'].std()}.\\n\")\n",
    "\n",
    "# Get 'Intensity' (Series) median\n",
    "print(f\"Median: {df['Intensity'].median()}.\\n\")\n",
    "\n",
    "# Get 'Intensity' (Series) minimum value\n",
    "print(f\"Minimum: {df['Intensity'].min()}.\\n\")\n",
    "\n",
    "# Get 'Intensity' (Series) maximum value\n",
    "print(f\"Maximum: {df['Intensity'].max()}.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful method is [`.quantile()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.quantile.html) (note that the default value this method is `0.5`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 'Intensity' (Series) 50 % percentile value\n",
    "print(f\"Percentile  50 %: {df['Intensity'].quantile()} (default).\\n\")\n",
    "\n",
    "# Get 'Intensity' (Series) 50 % percentile value\n",
    "print(f\"Percentile  50 %: {df['Intensity'].quantile(0.5)}.\\n\")\n",
    "\n",
    "# Get 'Intensity' (Series) 0 % percentile value\n",
    "print(f\"Percentile   0 %: {df['Intensity'].quantile(0)}.\\n\")\n",
    "\n",
    "# Get 'Intensity' (Series) 100 % percentile value\n",
    "print(f\"Percentile 100 %: {df['Intensity'].quantile(1)}.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns with non-numerical data also have cool methods, like: [`.unique()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.unique.html), [`.nunique()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.nunique.html), [`.value_counts()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html),..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 'Node' (Series) unique values\n",
    "print(f\"Unique values: {df['Node'].unique()}.\\n\")\n",
    "\n",
    "# Get 'Node' (Series) number of unique values\n",
    "print(f\"Number of unique values: {df['Node'].nunique()}.\\n\")\n",
    "\n",
    "# Get 'Node' (Series) count of each unique values\n",
    "print(f\"Count of unique values:\\n{df['Node'].value_counts()}.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DataFrame boolean indexing\n",
    "\n",
    "Do you remember the six *comparison operators*? \n",
    "+ `==`: Equal.\n",
    "+ `!=`: Not equal.\n",
    "+ `>`: Greater than.\n",
    "+ `<`: Less than.\n",
    "+ `>=`: Greater than or equal to.\n",
    "+ `<=`: Less than or equal to.\n",
    "\n",
    "We can use them to know which DataFrame rows affirmatively \"answer\" our \"question\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Has the current index, 'Intensity' greater than 100?\n",
    "df['Intensity'] > 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output translates as follows: `'Intensity'` values stored in DataFrame rows `0`, `2`, `4`, `5` and `11` are greater than `100`. Furthermore, we can also use the *logical operators* `and`, `or`, `not`, but in their *bitwise* form (`&`, `|`, `~`, respectively) to link multiple \"questions\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Has the current index, 'Intensity' greater than 100 AND 'Amplitude' smaller than 1.6?\n",
    "(df['Intensity'] > 100) & (df['Amplitude'] < 1.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Has the current index, 'Software' not equal to 'PD' OR 'Node' equal to 'Amanda'?\n",
    "(df['Software'] != 'PD') | (df['Node'] == 'Amanda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "<b>Caveat:</b> Keep in mind that DataFrame \"questions\" should be enclosed by parenthesis before linking them using the *logical operators* in their *bitwise* form: `&`, `|`, `~`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Practice 3:</b>\n",
    "\n",
    "1) In the 1<sup>st</sup> code cell below, ask our DataFrame `df` to get which rows present an `'Intensity'` lower than `90` **or** higher than `140`, **and**, a `'Node'` named `'Andromeda'` **or** `'Amanda'`.\n",
    "2) Inspect the DataFrame `df` and verify that boolean indexation is giving the correct answers.    \n",
    "\n",
    "Un-comment and fill only those code lines with underscores `___`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ejercicio"
    ]
   },
   "outputs": [],
   "source": [
    "# (1st code cell)\n",
    "# Has the current index, 'Software' not equal to 'PD' OR 'Node' equal to 'Amanda'?\n",
    "#( (df['Intensity'] _ ___) _ (df['Intensity'] _ ___) ) & ( (df['Node'] _ '___') _ (df['Node'] _ '___') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "ejercicio",
     "solucion"
    ]
   },
   "outputs": [],
   "source": [
    "# (1st code cell --> SOLUTION)\n",
    "#  Has the current index, 'Intensity' lower than 90 OR higher than 140, AND, 'Node' equal to Andromeda OR equal to 'Amanda'?\n",
    "( (df['Intensity'] < 90) | (df['Intensity'] > 140) ) & ( (df['Node'] == 'Andromeda') | (df['Node'] == 'Amanda') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Practice 3 ends here.</b>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering DataFrames with boolean indexing\n",
    "\n",
    "You can store the output of a boolean indexing into a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filter to get Proteome Discoverer software AND not to get Amanda search node\n",
    "series_bool = (df['Software'] == 'PD') & (df['Node'] != 'Amanda')\n",
    "\n",
    "# Get the variable type of `series_bool`\n",
    "type(series_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output of a boolean indexation (question) is a Pandas Series, in particular a Series full of boolean values, AKA, a *boolean Series* (answer). We can use such *boolean Series* to easily filter *DataFrames* in a very flexible way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying my (first) filter to my DataFrame\n",
    "df[series_bool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Tip:</b> You can rethink a *boolean Series* as a DataFrame \"mask\" that leaves uncovered only those rows of your interest.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Practice 4:</b>\n",
    "\n",
    "In the 1<sup>st</sup> code cell below, we already computed for you the 60 % quantile of the 'Intensity' `I_quantile` and the 40 % quantile of the 'Amplitude' `A_quantile`. Use this two variables to:\n",
    "    \n",
    "1) In the 2<sup>nd</sup> code cell below, create a boolean Series called `first_filter` to filter high intensity values (`> I_quantile`) **or** low amplitude values (`< A_quantile`) from the DataFrame `df`.\n",
    "2) In the 3<sup>rd</sup> code cell below, use `first_filter` to get your rows of interest from the *DataFrame* `df`.\n",
    "3) What you should change when creating `first_filter` if you would prefer high intensity values **and** low amplitude values. Create a boolean Series called `second_filter` for this purpose in the 3<sup>rd</sup> cell below, and get your new rows of interest from the *DataFrame* `df`.\n",
    "    \n",
    "Uncomment and fill only those code lines with underscores `___`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ejercicio"
    ]
   },
   "outputs": [],
   "source": [
    "# (1st code cell)\n",
    "# Retrieving the 60 % quantile of the 'Intensity': I_quantile\n",
    "I_quantile = df['Intensity'].quantile(0.60)\n",
    "print(I_quantile)\n",
    "\n",
    "# Retrieving the 40 % quantile of the 'Amplitude': A_quantile\n",
    "A_quantile = df['Amplitude'].quantile(0.40)\n",
    "print(A_quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ejercicio"
    ]
   },
   "outputs": [],
   "source": [
    "# (2nd code cell)\n",
    "#  Create filter to get high peak intensity (first 60 % quantile) OR low peak amplitude (last 40 % quantile)\n",
    "#first_filter = ___\n",
    "\n",
    "# Applying first filter to DataFrame\n",
    "#df[___]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "lines_to_next_cell": 2,
    "tags": [
     "ejercicio",
     "solucion"
    ]
   },
   "outputs": [],
   "source": [
    "# (2nd code cell --> SOLUTION) \n",
    "#  Create filter to get high peak intensity (first 60 % quantile) OR low peak amplitude (last 40 % quantile)\n",
    "first_filter = (df['Intensity'] > I_quantile) | (df['Amplitude'] < A_quantile)\n",
    "\n",
    "# Applying first filter to DataFrame\n",
    "df[first_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ejercicio"
    ]
   },
   "outputs": [],
   "source": [
    "# (3rd code cell)\n",
    "# Create filter to get high peak intensity (first 60 % quantile) AND low peak amplitude (last 40 % quantile)\n",
    "#second_filter = \n",
    "\n",
    "# Applying second filter to DataFrame\n",
    "#df[___]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "ejercicio",
     "solucion"
    ]
   },
   "outputs": [],
   "source": [
    "# (3rd code cell --> SOLUTION)\n",
    "# Create filter to get high peak intensity (first 60 % quantile) AND low peak amplitude (last 40 % quantile)\n",
    "second_filter = (df['Intensity'] > I_quantile) & (df['Amplitude'] < A_quantile)\n",
    "\n",
    "# Applying second filter to DataFrame\n",
    "df[second_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Practice 4 ends here.</b>\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "04_Pandas.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
