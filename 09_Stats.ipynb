{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MMRES-PyBootcamp/MMRES-python-bootcamp2024/blob/master/08_scipy_stats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqAIqBlSmD4w"
   },
   "source": [
    "# Session 8 - Statistics in Python (Second part - 50')\n",
    "\n",
    "\n",
    "> A very (very) basic introduction on statistics in Python. In this first introductory lesson we will just present some *Measures of Central Tendency* (median, mean and weighted mean) and *Measures of Variability* (variance and standard deviation). We will also talk about *Percentiles* and *Missing values*.\n",
    "> \n",
    "TODO\n",
    "\n",
    "sources:\n",
    "\n",
    "https://medium.com/insights-school/learn-basic-statistics-with-python-cc0f45275929\n",
    "\n",
    "https://scipy-lectures.org/intro/scipy.html#scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "86WqXweTk9Jh"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import statistics\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TODO\n",
    "import plotnine as p9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    " * [Loading a dataset](#Loading-a-dataset) \n",
    " * [Pearson correlation](#Pearson-correlation)\n",
    " * [Spearman correlation](#Spearman-correlation)\n",
    " * [Linear regression](#Linear-regression)\n",
    " * [Student's t-test](#Student's-t-test)\n",
    "   * [One-sample t-test](#One-sample-t-test)\n",
    "   * [Two-sample t-test (Independent samples t-test)](#Two-sample-t-test-(Independent-samples-t-test))\n",
    "   * [Paired-samples t-test (Dependent samples t-test)](#Paired-samples-t-test-(Dependent-samples-t-test))\n",
    "\n",
    "Linear models, multiple factors, and analysis of variance\n",
    "\n",
    "Categorical variables\n",
    "\n",
    "Link to t-tests between different FSIQ and PIQ\n",
    "\n",
    "Multiple Regression\n",
    "\n",
    "Analysis of variance (ANOVA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document is devised as a tool to enable your **self-learning process**. If you get stuck at some step or need any kind of help, please don't hesitate to raise your hand and ask for the teacher's guidance. Along it, you will find some **special cells**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Practice:</b> Practice cells announce exercises that you should try during the current boot camp session. Usually, solutions are provided using hidden cells (look for the dot dot dot symbol \"...\" and click to unravel them and check that your try is correct).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Extension:</b> Extension cells correspond to exercises (or links to contents) that are a bit more advanced. We recommend to try them after the current boot camp session.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> Tip cells just give some advice or complementary information.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"><b>Caveat:</b> Caveat cells warn you about the most common pitfalls one founds when starts his/her path learning Python.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a dataset\n",
    "\n",
    "Let's stats by loading a dataset from this cool [online resource](https://lectures.scientific-python.org/packages/statistics/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FWO0aVaNX09J",
    "outputId": "518b36bc-014c-45e5-a0f8-58d66109069d"
   },
   "outputs": [],
   "source": [
    "# Loading the \"Brain Size\" dataset directly from an URL\n",
    "df = pd.read_csv(\n",
    "    filepath_or_buffer='https://scipy-lectures.org/_downloads/brain_size.csv',\n",
    "    sep=';',\n",
    "    na_values=\".\",\n",
    "    index_col=0\n",
    ")\n",
    "\n",
    "# Show df's head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns *FSIQ*, *VIQ* and *PIQ* stand for different \"intelligence quotients\" (in arbitrary units I guess) and the *MRI_Count* is another \"intelligence\" measure based on magnetic resonance imaging (also in some kind of arbitrary unit I guess). The columns *Gender*, *Weight* and *Height* express the gender, the weight (in pounds) and the height (in inches) of the individuals, respectively. Before starting, let's express *Weight* and *Height* column values to metric units to avoid an eventual [Mars probe crash](https://www.simscale.com/blog/nasa-mars-climate-orbiter-metric/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from imperial units to metric units\n",
    "df['Weight_kg'] = df['Weight'] * 0.45359237\n",
    "df['Height_m'] = df['Height'] * 0.0254\n",
    "\n",
    "# Drop imperial columns\n",
    "df.drop(columns=['Weight', 'Height'], inplace=True)\n",
    "\n",
    "# Show df's head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ix17XAAGderf"
   },
   "source": [
    "## Pearson correlation\n",
    "We can compute the [Pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) using the [`pearsonr()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html) function from **SciPy**'s stats module. This function takes two arrays and returns a tuple containing **Pearson correlation coefficient** and the **significance of the correlation** as p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mjQFwowBddxx",
    "outputId": "89bc7053-937e-464f-9960-7096942a4a62"
   },
   "outputs": [],
   "source": [
    "# Get Pearson between 'FSIQ' and 'VIQ' using SciPy\n",
    "stats.pearsonr(x=df['FSIQ'], y=df['VIQ'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the Pearson correlation coefficient using the [`.corr()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html) **Pandas** method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E4q8Wp20fC8x",
    "outputId": "5733cbac-5cb0-4b2d-fa7b-fbbd1727f677"
   },
   "outputs": [],
   "source": [
    "# Get Pearson between 'FSIQ' and 'VIQ' using Pandas\n",
    "df['FSIQ'].corr(df['VIQ'], method=\"pearson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look what happens when we apply this `.corr()` method to a Dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Pearson for all pair-wise pairs 'FSIQ' and 'VIQ' using Pandas\n",
    "df[['FSIQ', 'VIQ']].corr(method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the **Pandas** method `corr()` on a dataframe, we obtain all possible pair-wise correlations nicely displayed in a \"square\" dataframe (or matrix). Let's try this strategy again on the whole `df` dataframe (note the trick of the `numeric_only=` argument to avoid the error that pops up when trying to compute correlations involving the `'Gender'` column):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all pair-wise Pearson from our df\n",
    "df_PCC = df.corr(method='pearson', numeric_only=True)\n",
    "\n",
    "# Show the Pearson correlation matrix\n",
    "df_PCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's leverage Seaborn [`.heatmap()`](https://seaborn.pydata.org/generated/seaborn.heatmap.html) to visualize this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the correlation matrix (HEATMAP!)\n",
    "sns.heatmap(data=df_PCC, cmap=\"Blues\", annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that *FSIQ*, *VIQ* and *PIQ* are very correlated, and similarly, *Weight [kg]*, *Height [m]* and (to a lesser extend) *MRI_Count*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1kiezr-eb-G"
   },
   "source": [
    "## Spearman correlation\n",
    "\n",
    "Pearson correlation assumes that the data we are comparing is <u>**normally distributed**</u>. When this assumption is not true, the Pearson correlation value is not reflecting the true association. Spearman correlation does not assume that data follows a specific distribution, so it is a non-parametric correlation measure. Spearman correlation is also known as Spearman's rank correlation as it computes correlation coefficient on rank values of the data. Using **SciPy**, we can compute Spearman correlation using the function `spearmanr()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eILWzQ2geU-2",
    "outputId": "40f10bc2-bb7d-48a1-e88f-caa81508ee5c"
   },
   "outputs": [],
   "source": [
    "#The first element of tuple is the Spearman's rank correlation and the second is p-value.\n",
    "stats.spearmanr(a=df['FSIQ'], b=df['VIQ'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b> Tip:</b> I don't know why `stats.pearsonr()` uses `x=` and `y=` as argument names and `stats.spearmanr()` uses `a=` and `b=`. In any case, you can use these two functions without specifying argument names: `stats.pearsonr(df['FSIQ'], df['VIQ'])` or `stats.spearmanr(df['FSIQ'], df['VIQ'])`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can also get the Spearman correlation coefficient using the [`.corr()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html) **Pandas** method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T9hqfdlTfR-P",
    "outputId": "c15006c1-dd0b-41c8-92c1-33a3cf4a86dd"
   },
   "outputs": [],
   "source": [
    "# Get Spearman between 'FSIQ' and 'VIQ' using Pandas\n",
    "df['FSIQ'].corr(df['VIQ'], method=\"spearman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use the Seaborn function [`clustermap()`](https://seaborn.pydata.org/generated/seaborn.clustermap.html) instead of `heatmap()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all pair-wise Spearman from our df\n",
    "df_ECC = df.corr(method='spearman', numeric_only=True)\n",
    "\n",
    "# Show the Spearman correlation matrix\n",
    "df_ECC\n",
    "\n",
    "# Plot the Spearman correlation matrix (CLUSTERMAP!)\n",
    "sns.clustermap(data=df_ECC, cmap=\"Reds\", annot=True, z_score=None, figsize=(6,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the [dendrogram](https://en.wikipedia.org/wiki/Dendrogram) and note how it hierarchizes closer those variables more correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "\n",
    "With the **SciPy** function [`linregress()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html) it's very easy to perform a linear regression and get all required coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a linear regression between 'FSIQ' and 'VIQ' using SciPy\n",
    "stats.linregress(x=df['FSIQ'], y=df['VIQ'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how `stats.linregress()` returns an object storing five values: `slope`, `intercept`, `rvalue`, `pvalue`, `stderr` and `intercept_stde`. You can assign the output of `stats.linregress()` in a variable and easily access its elements as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a linear regression between 'FSIQ' and 'VIQ' using SciPy\n",
    "FitResults = stats.linregress(x=df['FSIQ'], y=df['VIQ'])\n",
    "\n",
    "# Return the 'rvalue' (Pearson correlation) generated by the linear regression\n",
    "FitResults.rvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using some f-string trickery we can easily prepare a nice annotation with the regression line equation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather the regression line equation (using just 3 decimal places with the :.3f trick)\n",
    "annotation = f'y(x) = {FitResults.slope:.3f} x + {FitResults.intercept:.3f}'\n",
    "\n",
    "# Show the regression line equation\n",
    "print(annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use **Seaborn** to visualize the regression line along with the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "rU2CCDm-hmAX",
    "outputId": "571d0105-0696-4147-85f0-a9f60b8df214"
   },
   "outputs": [],
   "source": [
    "# Create the scatter plot with Seaborn\n",
    "p = sns.scatterplot(data=df, x=\"FSIQ\", y=\"VIQ\", hue=\"Gender\")\n",
    "\n",
    "# Add the linear regression line (by hand) with Matplotlib\n",
    "p.axline(xy1=(0, FitResults.intercept), slope=FitResults.slope, color='lightgray')\n",
    "\n",
    "# Adjust scatter plot limits (by hand) with Matplotlib\n",
    "p.set_xlim(df[\"FSIQ\"].min()-2, df[\"FSIQ\"].max()+2)\n",
    "p.set_ylim(df[\"VIQ\"].min()-2, df[\"VIQ\"].max()+2) \n",
    "\n",
    "# Add regression line equation (by hand) with Matplotlib\n",
    "plt.text(95, 145, annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With **Plotnine** we can also get a very nice plot (maybe with less tweaking):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = (\n",
    "    \n",
    "    # Create the scatter plot with Plotnine\n",
    "    p9.ggplot(data=df, mapping=p9.aes(x=\"FSIQ\", y=\"VIQ\", color=\"Gender\"))\n",
    "     + p9.geom_point()\n",
    "\n",
    "    # Add the linear regression line (by hand)\n",
    "     + p9.geom_abline(intercept=FitResults.intercept, slope=FitResults.slope, color='lightgray')\n",
    "\n",
    "    # Add regression line equation (by hand)\n",
    "     + p9.annotate(geom=\"text\", x=95, y=145, label=annotation)\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "gg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MVaeENVgarVN"
   },
   "source": [
    "## Student's t-test\n",
    "\n",
    "A t-test is a statistical tool used to determine if there is a significant difference between the means of two groups, or between the mean of one group and a known value. There are three kinds of t-tests: **One-Sample t-test**, **Two-sample t-test** and **Paired samples t-test**.\n",
    "\n",
    "### One-sample t-test\n",
    "\n",
    "The one-sample t-test is used to **compare the mean of a single group to a known or hypothesized value**. This test is appropriate when you want to determine if a sample comes from a population with a specific mean. **SciPy** has implemented a function to perform one-sample t-test: [`scipy.stats.ttest_1samp()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_1samp.html). Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represent the distribution traced by VIQ and mark its mean\n",
    "sns.kdeplot(data=df, x=\"VIQ\", color='blue', fill='blue', alpha=0.1)\n",
    "plt.axvline(x=df['VIQ'].mean(), color='blue')\n",
    "\n",
    "# Mark a couple of arbitrary values\n",
    "plt.axvline(x=100, color='red')\n",
    "plt.axvline(x=105, color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test if the difference between the mean of *VIQ* and $105$ is significant, we should do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launching a 1STT to check if VIQ mean differs than 105\n",
    "stats.ttest_1samp(a=df['VIQ'], popmean=105)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns an object with the **T statistic**, the **p-value** and the **degrees of freedom**. If, for example, we assume a significance level of $0.05$, we cannot say that the mean of *VIQ* is different than $105$. In contrast, with this same significance level, we can say that the mean of *VIQ* is different than $100$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launching a 1STT to check if VIQ mean differs than 100\n",
    "stats.ttest_1samp(a=df['VIQ'], popmean=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWNrJWvlb4nY"
   },
   "source": [
    "### Two-sample t-test (Independent samples t-test)\n",
    "\n",
    "The two-sample t-test is used to **compare the means of two unrelated groups**. The term \"unrelated\" means that the two groups are not related to each other (different patients with and without a given clinical condition for example). **SciPy** has implemented a function to perform two-sample t-test: [`scipy.stats.ttest_ind()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html). For example, let's compare the mean *VIQ* between females and males:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Gender' and get the mean VIQ\n",
    "df_g = df.groupby(by='Gender').agg(Mean_VIQ=('VIQ', 'mean'))\n",
    "\n",
    "# Show the data frame\n",
    "df_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represent the distribution traced by VIQ differentiating males and females\n",
    "sns.kdeplot(data=df, x=\"VIQ\", hue='Gender', fill='Gender')\n",
    "\n",
    "# Mark the mean VIQ for males (orange) and females (blue)\n",
    "plt.axvline(x=df_g['Mean_VIQ']['Male'], color=sns.color_palette()[0])\n",
    "plt.axvline(x=df_g['Mean_VIQ']['Female'], color=sns.color_palette()[1])\n",
    "# Note how we used the same default colors used by Seaborn with sns.color_palette()[ ] ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the mean *VIQ* is slightly different between genders, but is this difference *statistically significant*? Let's check it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vSeXznL6a3wq",
    "outputId": "851cde28-7c90-42bc-ffbc-fafc6c07b17a"
   },
   "outputs": [],
   "source": [
    "# Prepare filters for females and males\n",
    "filter_F = df['Gender'] == 'Female'\n",
    "filter_M = df['Gender'] == 'Male'\n",
    "\n",
    "# Launching a 2STT to check if VIQ mean differs between females and males\n",
    "stats.ttest_ind(df[filter_F]['VIQ'], df[filter_M]['VIQ'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming again the typical significance level of $0.05$, we cannot report a significant *VIQ* different between genders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opYcYwwYbY1-"
   },
   "source": [
    "### Paired-samples t-test (Dependent samples t-test)\n",
    "\n",
    "Finally, the paired samples t-test is used to **compare the means of two related groups**. Here, the term \"related\" denotes that the groups are not independent (same patients before and after a treatment for example). **SciPy** implements a function to perform paired-samples t-test: [`scipy.stats.ttest_rel()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_rel.html). In the previous example we compared *VIQ* between females and males (independent groups). Now, let's compare the three IQ estimators provided in our data set (*PIQ*, *VIQ*, and *FSIQ*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Tip:</b> We want to visualize the three IQ estimators in a same plot to better glimpse whats going on. In order to easily do that leveraging Seaborn, we first need to tweak a bit the original data frame `df` by melting it. By the way, we will also get the mean for each IQ estimator as we just did to get the mean <i>VIQ</i> for females and males.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melting our data frame to better visualize it with Seaborn\n",
    "df_m = pd.melt(frame=df, id_vars=None, value_vars=['PIQ', 'VIQ', 'FSIQ'], var_name='IQ type', value_name='IQ value') \n",
    "\n",
    "# Show the data frame\n",
    "df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'IQ type' and get the mean IQ\n",
    "df_g = df_m.groupby(by='IQ type').agg(Mean_IQ=('IQ value', 'mean'))\n",
    "\n",
    "# Show the data frame\n",
    "df_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represent the distribution traced by each IQ type\n",
    "sns.kdeplot(data=df_m, x=\"IQ value\", hue='IQ type', fill='IQ type')\n",
    "\n",
    "# Mark the mean IQ for each IQ type: PIQ (blue), VIQ (orange), FSIQ (green)\n",
    "plt.axvline(x=df_g['Mean_IQ']['PIQ'], color=sns.color_palette()[0])\n",
    "plt.axvline(x=df_g['Mean_IQ']['VIQ'], color=sns.color_palette()[1])\n",
    "plt.axvline(x=df_g['Mean_IQ']['FSIQ'], color=sns.color_palette()[2])\n",
    "# Note how we used the same default colors used by Seaborn with sns.color_palette()[ ] ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first sight, all three IQ estimators exhibit quite alike bimodal distributions with very similar means for `IQ value`. Now, let's check it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launching a PSTT to check if PIQ mean differs from VIQ mean\n",
    "print(stats.ttest_rel(df['PIQ'], df['VIQ']))\n",
    "\n",
    "# Launching a PSTT to check if PIQ mean differs from FSIQ mean\n",
    "print(stats.ttest_rel(df['PIQ'], df['FSIQ']))\n",
    "\n",
    "# Launching a PSTT to check if VIQ mean differs from FSIQ mean\n",
    "print(stats.ttest_rel(df['VIQ'], df['FSIQ']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming again a significance level of $0.05$, we cannot report a significant difference between the three IQ estimators available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Tip:</b> Imagine that (instead of three IQ estimators) you have, let's say, one hundred. Getting all possible pairs and writing the corresponding statistical tests by hand could be dangerous. In these situations you should <i>loop</i> along all possible pair combinations:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the itertools package\n",
    "import itertools\n",
    "\n",
    "# Define a list with all our IQ estimators\n",
    "list_IQs = ['PIQ', 'VIQ', 'FSIQ']\n",
    "\n",
    "# Get a list with all possible list_IQs combinations pairs (repeat=2)\n",
    "list_IQ_pairs = itertools.combinations(iterable=list_IQs, r=2) \n",
    "\n",
    "# Loop along all possible pairs...\n",
    "for pair in list_IQ_pairs:\n",
    "    \n",
    "    #... print the running pair and its corresponding paired samples t-test outcome\n",
    "    print(pair, stats.ttest_rel(df[pair[0]], df[pair[1]]), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>Extension:</b> You can also achieve this with a **list comprehension** instead of a **for loop**:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list with all our IQ estimators\n",
    "list_IQs = ['PIQ', 'VIQ', 'FSIQ']\n",
    "\n",
    "# Get a list with all possible list_IQs combinations pairs (repeat=2)\n",
    "list_IQ_pairs = itertools.combinations(iterable=list_IQs, r=2) \n",
    "\n",
    "# Give a tuple ( , ) with the running pair and its corresponding paired samples t-test outcome for all possible pairs\n",
    "[( pair, stats.ttest_rel(df[pair[0]], df[pair[1]]) ) for pair in list_IQ_pairs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "<b>Practice 1:</b> Test if the weight for females and males is different using a t-test.\n",
    "\n",
    "1) Which t-test will you use (one-, two- or paired-sample t-test)? Why?\n",
    "2) In the 1<sup>st</sup> code cell below, use the chosen t-test to statistically evaluate the weight difference between females and males. What happened in this first try?\n",
    "3) In the 2<sup>nd</sup> code cell below, try again with the `stats.ttest_***()` argument `nan_policy='omit'`. What happened in this second try? What was the outcome of your t-test?\n",
    "4) In the 3<sup>rd</sup> code cell below, prepare a nice plot showing the weight distribution for females and males, marking their corresponding mean values with vertical lines.\n",
    "\n",
    "<b>Note:</b> Uncomment and fill only those code lines with underscores `___`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1st code cell)\n",
    "\n",
    "# Prepare filters for females and males\n",
    "#filter_F = ___\n",
    "#filter_M = ___\n",
    "\n",
    "# Launching a 2STT to check if the weight mean differs between females and males\n",
    "#stats.___(___, ___)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# (1st code cell --> SOLUTION)\n",
    "\n",
    "# Prepare filters for females and males\n",
    "filter_F = df['Gender'] == 'Female'\n",
    "filter_M = df['Gender'] == 'Male'\n",
    "\n",
    "# Launching a 2STT to check if the weight mean differs between females and males\n",
    "stats.ttest_ind(df[filter_F]['Weight [kg]'], df[filter_M]['Weight [kg]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2nd code cell)\n",
    "\n",
    "# Launching a 2STT to check if the weight mean differs between females and males\n",
    "#stats.___(___, ___, ___)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# (2nd code cell --> SOLUTION)\n",
    "\n",
    "# Launching a 2STT to check if the weight mean differs between females and males\n",
    "stats.ttest_ind(df[filter_F]['Weight [kg]'], df[filter_M]['Weight [kg]'], nan_policy='omit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3rd code cell)\n",
    "\n",
    "# Group by 'Gender' and get the mean weight\n",
    "#df_g = df.groupby(by=___).agg(Mean_Weight_kg=(___, ___))\n",
    "\n",
    "# Show the data frame\n",
    "#print(df_g)\n",
    "\n",
    "# Represent the distribution traced by weight differentiating males and females\n",
    "#sns.kdeplot(data=___, x=___, hue=___, fill=___)\n",
    "\n",
    "# Mark the mean weight for males (orange) and females (blue)\n",
    "#plt.axvline(x=___['Mean_Weight_kg'][___], color=sns.color_palette()[___])\n",
    "#plt.axvline(x=___['Mean_Weight_kg'][___], color=sns.color_palette()[___])\n",
    "# Note how we used the same default colors used by Seaborn with sns.color_palette()[ ] ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# (3rd code cell --> SOLUTION)\n",
    "\n",
    "# Group by 'Gender' and get the mean weight\n",
    "df_g = df.groupby(by='Gender').agg(Mean_Weight_kg=('Weight [kg]', 'mean'))\n",
    "\n",
    "# Show the data frame\n",
    "print(df_g)\n",
    "\n",
    "# Represent the distribution traced by weight differentiating males and females\n",
    "sns.kdeplot(data=df, x='Weight [kg]', hue='Gender', fill='Gender')\n",
    "\n",
    "# Mark the mean weight for males (orange) and females (blue)\n",
    "plt.axvline(x=df_g['Mean_Weight_kg']['Female'], color=sns.color_palette()[0])\n",
    "plt.axvline(x=df_g['Mean_Weight_kg']['Male'], color=sns.color_palette()[1])\n",
    "# Note how we used the same default colors used by Seaborn with sns.color_palette()[ ] ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Practice 1 ends here.</b>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQ9McOP0czi0"
   },
   "source": [
    "# Linear models, multiple factors, and analysis of variance\n",
    "Given two set of observations, x and y, we want to test the hypothesis that y is a linear function of x. In other terms:\n",
    "\n",
    "> y = ax + b + e\n",
    "\n",
    "where e is observation noise. We will use the statsmodels module to:\n",
    "\n",
    "Fit a linear model. We will use the simplest strategy, ordinary least squares (OLS).\n",
    "Test that coef is non zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o-H_pqIEcnDo"
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-5, 5, 20)\n",
    "x2= np.linspace(0,10, 20)\n",
    "x3=  np.random.normal(size=20)\n",
    "\n",
    "np.random.seed(1)\n",
    "# normal distributed noise\n",
    "y = -5 + 3*x -10*x2 + 4 * np.random.normal(size=x.shape)\n",
    "# Create a data frame containing all the relevant variables\n",
    "data = pd.DataFrame({'x': x,'x2': x2, 'x3':x3, 'y': y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-5 + 4*np.random.normal(size=x.shape).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "IrfHZDdXe_3P",
    "outputId": "6842f0f3-aa6f-4fd7-cc77-1998690b29e7"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols(\"Weight_kg ~ Height_m + 1\", df).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df, x='Height_m', y='Weight_kg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eecqvySgdmHq"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DOuOGkQMdjIz",
    "outputId": "b260c3e4-ce2c-4396-fb19-9cb0b16313ca"
   },
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "model = ols(\"y ~ x + x2 + x3\", data).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWslokQ4mrd6"
   },
   "source": [
    "## Categorical variables:\n",
    " comparing groups or multiple categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "81HPs71YmqfZ",
    "outputId": "7ebdd26e-9e4b-44d7-b9ff-afc4667507a1"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://scipy-lectures.org/_downloads/brain_size.csv', sep=';', na_values=\".\")\n",
    "model = ols(\"VIQ ~ Gender + 1\", data).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWX588mpnIez"
   },
   "source": [
    "\n",
    "## Link to t-tests between different FSIQ and PIQ\n",
    "\n",
    "To compare different types of IQ, we need to create a “long-form” table, listing IQs, where the type of IQ is indicated by a categorical variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 722
    },
    "id": "NiuWkDTPnHny",
    "outputId": "2eee0087-70a0-418b-abde-35fc989b7311"
   },
   "outputs": [],
   "source": [
    "data_fisq = pd.DataFrame({'iq': data['FSIQ'], 'type': 'fsiq'})\n",
    "data_piq = pd.DataFrame({'iq': data['PIQ'], 'type': 'piq'})\n",
    "data_long = pd.concat((data_fisq, data_piq))\n",
    "print(data_long)\n",
    "\n",
    "#sns.boxplot(data=data_long,x='type',y='iq')\n",
    "sns.violinplot(data=data_long,x='type',y='iq')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "85zfO1j_nZuQ",
    "outputId": "0fa1f02f-55a6-4f8a-9060-4d4833504b02"
   },
   "outputs": [],
   "source": [
    "model = ols(\"iq ~ type\", data_long).fit()\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bizizr1OndAv"
   },
   "source": [
    "## Multiple Regression:\n",
    "including multiple factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ApeDiDzgnctM",
    "outputId": "b2b98121-0242-43ad-a4cb-e5feae1de98f"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://scipy-lectures.org/_downloads/iris.csv')\n",
    "model = ols('sepal_width ~ name + petal_length', data).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7VmJAkzoDy9"
   },
   "source": [
    "# Analysis of variance (ANOVA)\n",
    "In the above iris example, we wish to test if the petal length is different between versicolor and virginica, after removing the effect of sepal width. This can be formulated as testing the difference between the coefficient associated to versicolor and virginica in the linear model estimated above (it is an Analysis of Variance, ANOVA). For this, we write a vector of ‘contrast’ on the parameters estimated: we want to test \"name[T.versicolor] - name[T.virginica]\", with an F-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iix02Vn9oqZd",
    "outputId": "c5cc0ebe-35cc-4014-ec74-58aac40e29db"
   },
   "outputs": [],
   "source": [
    "print(model.f_test([0, 1, -1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "08_scipy_stats.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
